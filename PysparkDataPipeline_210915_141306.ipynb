{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Achrafech/-Hackathon-GIS-in-the-heart-of-smart-cities-SIGINOV-/blob/main/PysparkDataPipeline_210915_141306.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ojpNoVscR-L",
        "outputId": "8e9eda5f-5f5f-4262-cc7e-9143724524f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.3)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bbkhKR1vcR-N"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "# Configure SparkSession for local mode\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master('local[2]') \\\n",
        "    .appName('quake_etl') \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXl7BfJcR-P",
        "outputId": "97ae4078-9256-46f0-f649-3f58f63807ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Date='01/02/1965', Time='13:44:18', Latitude='19.246', Longitude='145.616', Type='Earthquake', Depth='131.6', Depth Error=None, Depth Seismic Stations=None, Magnitude='6', Magnitude Type='MW', Magnitude Error=None, Magnitude Seismic Stations=None, Azimuthal Gap=None, Horizontal Distance=None, Horizontal Error=None, Root Mean Square=None, ID='ISCGEM860706', Source='ISCGEM', Location Source='ISCGEM', Magnitude Source='ISCGEM', Status='Automatic')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df_load = spark.read.csv(r\"/content/database.csv\", header=True)\n",
        "# Preview df_load\n",
        "df_load.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHabyw3ecR-R",
        "outputId": "394e23eb-5cea-4357-e972-b076020e03d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
            "|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|\n",
            "|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|\n",
            "|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|\n",
            "|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|\n",
            "|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Drop fields we don't need from df_load\n",
        "lst_dropped_columns = ['Depth Error', 'Time', 'Depth Seismic Stations','Magnitude Error','Magnitude Seismic Stations','Azimuthal Gap', 'Horizontal Distance','Horizontal Error',\n",
        "    'Root Mean Square','Source','Location Source','Magnitude Source','Status']\n",
        "\n",
        "df_load = df_load.drop(*lst_dropped_columns)\n",
        "# Preview df_load\n",
        "df_load.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDxhh9tTcR-R",
        "outputId": "76392a88-3d59-4447-ff7e-37447fb82a9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|01/02/1965|  19.246|  145.616|Earthquake|131.6|        6|            MW|ISCGEM860706|1965|\n",
            "|01/04/1965|   1.863|  127.352|Earthquake|   80|      5.8|            MW|ISCGEM860737|1965|\n",
            "|01/05/1965| -20.579| -173.972|Earthquake|   20|      6.2|            MW|ISCGEM860762|1965|\n",
            "|01/08/1965| -59.076|  -23.557|Earthquake|   15|      5.8|            MW|ISCGEM860856|1965|\n",
            "|01/09/1965|  11.938|  126.427|Earthquake|   15|      5.8|            MW|ISCGEM860890|1965|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a year field and add it to the dataframe\n",
        "df_load = df_load.withColumn('Year', year(to_timestamp('Date', 'dd/MM/yyyy')))\n",
        "# Preview df_load\n",
        "df_load.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkf6G8PXcR-S",
        "outputId": "959f754f-a4f1-4c37-f4d1-61f71ceb564a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|Year|Counts|\n",
            "+----+------+\n",
            "|1990|   196|\n",
            "|1975|   150|\n",
            "|1977|   148|\n",
            "|2003|   187|\n",
            "|2007|   211|\n",
            "+----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Build the quakes frequency dataframe using the year field and counts for each year\n",
        "df_quake_freq = df_load.groupBy('Year').count().withColumnRenamed('count', 'Counts')\n",
        "# Preview df_quake_freq\n",
        "df_quake_freq.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_A1cYmPcR-S",
        "outputId": "60a581a7-fa58-4b26-d929-b4ba32903078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Latitude: string (nullable = true)\n",
            " |-- Longitude: string (nullable = true)\n",
            " |-- Type: string (nullable = true)\n",
            " |-- Depth: string (nullable = true)\n",
            " |-- Magnitude: string (nullable = true)\n",
            " |-- Magnitude Type: string (nullable = true)\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview df_load schema\n",
        "df_load.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNWbmdvWcR-S",
        "outputId": "050a1274-8f2c-4ce2-d949-c5c729facae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n",
            "|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n",
            "|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n",
            "|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n",
            "|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Cast some fields from string into numeric types\n",
        "df_load = df_load.withColumn('Latitude', df_load['Latitude'].cast(DoubleType()))\\\n",
        "    .withColumn('Longitude', df_load['Longitude'].cast(DoubleType()))\\\n",
        "    .withColumn('Depth', df_load['Depth'].cast(DoubleType()))\\\n",
        "    .withColumn('Magnitude', df_load['Magnitude'].cast(DoubleType()))\n",
        "\n",
        "# Preview df_load\n",
        "df_load.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rONlJ9mccR-T",
        "outputId": "c263fc09-b69e-42e2-9f76-1b21feb12a7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Type: string (nullable = true)\n",
            " |-- Depth: double (nullable = true)\n",
            " |-- Magnitude: double (nullable = true)\n",
            " |-- Magnitude Type: string (nullable = true)\n",
            " |-- ID: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview df_load schema\n",
        "df_load.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gLPxaF05cR-T"
      },
      "outputs": [],
      "source": [
        "# Create avg magnitude and max magnitude fields and add to df_quake_freq\n",
        "df_max = df_load.groupBy('Year').max('Magnitude').withColumnRenamed('max(Magnitude)', 'Max_Magnitude')\n",
        "df_avg = df_load.groupBy('Year').avg('Magnitude').withColumnRenamed('avg(Magnitude)', 'Avg_Magnitude')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4UuC9nHcR-U",
        "outputId": "8bca3f65-3990-4006-dd56-32a0d32c7b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+-----------------+-------------+\n",
            "|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n",
            "+----+------+-----------------+-------------+\n",
            "|1990|   196|5.858163265306125|          7.6|\n",
            "|1975|   150| 5.84866666666667|          7.8|\n",
            "|1977|   148|5.757432432432437|          7.6|\n",
            "|2003|   187|5.850802139037435|          7.6|\n",
            "|2007|   211| 5.89099526066351|          8.4|\n",
            "+----+------+-----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Join df_max, and df_avg to df_quake_freq\n",
        "df_quake_freq = df_quake_freq.join(df_avg, ['Year']).join(df_max, ['Year'])\n",
        "# Preview df_quake_freq\n",
        "df_quake_freq.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83EZogKAcR-U",
        "outputId": "db1d5dae-a405-424e-83f7-26dc5e291660"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[Year: int, Counts: bigint, Avg_Magnitude: double, Max_Magnitude: double]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Remove nulls\n",
        "df_load.dropna()\n",
        "df_quake_freq.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4TYUrUTcR-V",
        "outputId": "70b0ea12-a537-48c8-bd78-fcdc5112c8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|01/02/1965|  19.246|  145.616|Earthquake|131.6|      6.0|            MW|ISCGEM860706|1965|\n",
            "|01/04/1965|   1.863|  127.352|Earthquake| 80.0|      5.8|            MW|ISCGEM860737|1965|\n",
            "|01/05/1965| -20.579| -173.972|Earthquake| 20.0|      6.2|            MW|ISCGEM860762|1965|\n",
            "|01/08/1965| -59.076|  -23.557|Earthquake| 15.0|      5.8|            MW|ISCGEM860856|1965|\n",
            "|01/09/1965|  11.938|  126.427|Earthquake| 15.0|      5.8|            MW|ISCGEM860890|1965|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview dataframes\n",
        "df_load.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alop9qCmcR-V",
        "outputId": "c98e2e95-06f0-4252-ea89-4303c191e75a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+-----------------+-------------+\n",
            "|Year|Counts|    Avg_Magnitude|Max_Magnitude|\n",
            "+----+------+-----------------+-------------+\n",
            "|1990|   196|5.858163265306125|          7.6|\n",
            "|1975|   150| 5.84866666666667|          7.8|\n",
            "|1977|   148|5.757432432432437|          7.6|\n",
            "|2003|   187|5.850802139037435|          7.6|\n",
            "|2007|   211| 5.89099526066351|          8.4|\n",
            "+----+------+-----------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_quake_freq.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPqZqol9cR-V",
        "outputId": "31c3a86e-2d8d-401c-83a3-bbf13a07e2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame saved as CSV file at: /content/quake_data.csv\n"
          ]
        }
      ],
      "source": [
        "output_path = \"/content/quake_data.csv\"\n",
        "df_load.write.format(\"csv\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .save(output_path)\n",
        "\n",
        "print(f\"DataFrame saved as CSV file at: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdzGl3FecR-W",
        "outputId": "541b346a-4600-4f23-e4c0-48fd336b77ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_quake_freq saved as CSV file at: /content/quake_freq_data.csv\n"
          ]
        }
      ],
      "source": [
        "output_path = \"/content/quake_freq_data.csv\"\n",
        "df_quake_freq.write.format(\"csv\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .save(output_path)\n",
        "\n",
        "print(f\"df_quake_freq saved as CSV file at: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AWpF7uiTcR-X",
        "outputId": "2ab9b8fe-d1ec-46ba-a872-5ec4eeef1e21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSection: Machine Learning with Spark\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\"\"\"\n",
        "Section: Machine Learning with Spark\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0X6dB3pQcR-X"
      },
      "outputs": [],
      "source": [
        "# Load data from the CSV file\n",
        "file_path = \"/content/quake_data.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "# Split the data into 80% training and 20% testing\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upp7cs2lcR-X",
        "outputId": "2fc88997-6f18-42ac-c0b4-61726f37b0d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DataFrame:\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|01/01/1967| -15.237| -173.608|Earthquake| 30.0|      6.5|            MW|ISCGEM839215|1967|\n",
            "|01/01/1967|   -11.2|  165.416|Earthquake| 30.0|      5.9|            MW|ISCGEM839250|1967|\n",
            "|01/01/1970|   -29.4| -177.169|Earthquake| 35.0|      5.6|            MW|ISCGEM799588|1970|\n",
            "|01/01/1971|   -4.19|  141.183|Earthquake| 35.0|      6.0|            MW|ISCGEM787816|1971|\n",
            "|01/01/1972| -17.021|  174.903|Earthquake| 10.0|      6.8|            MW|ISCGEM776618|1972|\n",
            "|01/01/1975|  -4.932|  129.923|Earthquake| 20.0|      5.7|            MB|  USP00009BY|1975|\n",
            "|01/01/1976| -28.949| -177.537|Earthquake| 50.0|      5.5|            MB|  USP0000E7J|1976|\n",
            "|01/01/1976| -28.611| -177.638|Earthquake| 59.0|      6.2|            MB|  USP0000E7F|1976|\n",
            "|01/01/1976| -16.786|  167.252|Earthquake| 25.0|      5.5|            MS|  USP0000E7Z|1976|\n",
            "|01/01/1976|  -16.59| -172.852|Earthquake| 33.0|      5.7|            MB|  USP0000E7Q|1976|\n",
            "|01/01/1977|  -2.532|  126.582|Earthquake| 33.0|      6.1|            MS|  USP0000M11|1977|\n",
            "|01/01/1977|  38.146|   91.007|Earthquake| 27.0|      6.3|            MS|  USP0000M14|1977|\n",
            "|01/01/1980|  38.815|   -27.78|Earthquake| 10.0|      6.7|            MS|  USP00014TU|1980|\n",
            "|01/01/1982| -17.954| -178.496|Earthquake|587.2|      5.5|            MB|  USP0001HU8|1982|\n",
            "|01/01/1982|  26.823|  142.557|Earthquake| 22.2|      6.7|            MS|  USP0001HUC|1982|\n",
            "|01/01/1984|  -22.81|   -66.16|Earthquake|272.1|      6.0|            MW|  USP00020ZF|1984|\n",
            "|01/01/1984|  -2.601|  141.597|Earthquake| 33.0|      5.5|            MW|  USP00020Z1|1984|\n",
            "|01/01/1984|  33.683|  136.894|Earthquake|368.1|      7.2|            MW|  USP00020Z7|1984|\n",
            "|01/01/1987|  -2.715|  138.363|Earthquake| 74.0|      5.6|            MW|  USP00031BC|1987|\n",
            "|01/01/1991| -21.208| -174.149|Earthquake| 29.1|      6.0|            MW|  USP0004K2N|1991|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview the training and testing DataFrames\n",
        "print(\"Training DataFrame:\")\n",
        "train_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing DataFrame:\")\n",
        "test_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwWI76newS-D",
        "outputId": "1a32b5ad-b456-4ad8-9910-09702c82ac16"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing DataFrame:\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|      Date|Latitude|Longitude|      Type|Depth|Magnitude|Magnitude Type|          ID|Year|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "|01/01/1969|  51.096| -179.392|Earthquake| 45.0|      5.6|            MW|ISCGEM812771|1969|\n",
            "|01/01/1973| -35.513|  -16.211|Earthquake| 33.0|      6.0|            MS|  USP0000004|1973|\n",
            "|01/01/1975|  61.909| -149.738|Earthquake| 66.0|      5.9|            MB|  USP00009BD|1975|\n",
            "|01/01/1977|  -7.885|  109.014|Earthquake|113.0|      5.7|            MB|  USP0000M10|1977|\n",
            "|01/01/1983| -16.943|  -69.114|Earthquake|172.0|      6.3|            MW|  USP0001RXV|1983|\n",
            "|01/01/1986|  19.282| -108.386|Earthquake| 10.0|      5.6|            MW|  USP0002PPD|1986|\n",
            "|01/01/1995|  40.701|  143.549|Earthquake| 15.2|      6.5|           MWB|  USP0006QPV|1995|\n",
            "|01/01/1997|  -0.127|  123.823|Earthquake|115.4|      5.8|           MWC|  USP0007VAQ|1997|\n",
            "|01/01/2004| -21.476|  169.859|Earthquake| 10.0|      5.5|           MWC|  USP000CGQ5|2004|\n",
            "|01/01/2004|   -8.31|  115.788|Earthquake| 44.5|      5.8|           MWB|  USP000CGSS|2004|\n",
            "|01/01/2004|   17.42| -101.315|Earthquake| 28.3|      5.7|           MWC|  USP000CGTD|2004|\n",
            "|01/01/2005|    2.91|   95.623|Earthquake| 24.5|      5.7|           MWB|  USP000DCB7|2005|\n",
            "|01/01/2005|   5.465|   94.398|Earthquake| 36.0|      5.7|           MWB|  USP000DCBA|2005|\n",
            "|01/01/2006|   4.735|   95.144|Earthquake| 51.5|      5.5|           MWB|  USP000E7B6|2006|\n",
            "|01/01/2011| -26.803|  -63.136|Earthquake|576.8|      7.0|           MWW|  USP000HSDC|2011|\n",
            "|01/02/1967| -10.187|   28.424|Earthquake| 29.1|      5.6|            MW|ISCGEM839280|1967|\n",
            "|01/02/1975|  46.884|  151.563|Earthquake| 52.0|      5.7|            MB|  USP00009C7|1975|\n",
            "|01/02/2000| -20.771| -174.236|Earthquake| 33.0|      5.8|           MWB|  USP0009KNU|2000|\n",
            "|01/02/2006| -60.957|  -21.606|Earthquake| 13.0|      7.4|           MWC|  USP000E7DD|2006|\n",
            "|01/02/2009|   0.624|  -26.661|Earthquake| 10.0|      5.6|           MWC|  USP000GS11|2009|\n",
            "+----------+--------+---------+----------+-----+---------+--------------+------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kMl3LHxcR-X",
        "outputId": "9b3fd14a-6595-4026-e901-e5ccd3393a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+---------+---------+-----+\n",
            "|      Date|Latitude|Longitude|Magnitude|Depth|\n",
            "+----------+--------+---------+---------+-----+\n",
            "|01/01/1969|  51.096| -179.392|      5.6| 45.0|\n",
            "|01/01/1973| -35.513|  -16.211|      6.0| 33.0|\n",
            "|01/01/1975|  61.909| -149.738|      5.9| 66.0|\n",
            "|01/01/1977|  -7.885|  109.014|      5.7|113.0|\n",
            "|01/01/1983| -16.943|  -69.114|      6.3|172.0|\n",
            "+----------+--------+---------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Select fields we will use and discard fields we don't need\n",
        "df_test_clean = test_df['Date', 'Latitude', 'Longitude', 'Magnitude', 'Depth']\n",
        "# Preview df_test_clean\n",
        "df_test_clean.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0R0M0HacR-Y",
        "outputId": "51cc3dac-78f6-4d85-8b88-1cfd2dcf67d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Magnitude: double (nullable = true)\n",
            " |-- Depth: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview Schema\n",
        "df_test_clean.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JUNorlcYcR-Y"
      },
      "outputs": [],
      "source": [
        "# Cast some string fields into numeric fields\n",
        "df_test_clean = df_test_clean.withColumn('Latitude', df_test_clean['Latitude'].cast(DoubleType()))\\\n",
        "    .withColumn('Longitude', df_test_clean['Longitude'].cast(DoubleType()))\\\n",
        "    .withColumn('Depth', df_test_clean['Depth'].cast(DoubleType()))\\\n",
        "    .withColumn('Magnitude', df_test_clean['Magnitude'].cast(DoubleType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIR8KWeLcR-Z",
        "outputId": "fdceae64-4ecc-4738-a8ef-a3fc36e68aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Latitude: double (nullable = true)\n",
            " |-- Longitude: double (nullable = true)\n",
            " |-- Magnitude: double (nullable = true)\n",
            " |-- Depth: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_test_clean.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Ed8KDehZcR-Z"
      },
      "outputs": [],
      "source": [
        "# Create training and testing dataframes\n",
        "df_testing = df_test_clean['Latitude', 'Longitude', 'Magnitude', 'Depth']\n",
        "df_training = train_df['Latitude', 'Longitude', 'Magnitude', 'Depth']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDsjOSf1cR-Z",
        "outputId": "db8ed03c-e401-48f6-eafa-f22bad88b72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+---------+-----+\n",
            "|Latitude|Longitude|Magnitude|Depth|\n",
            "+--------+---------+---------+-----+\n",
            "| -15.237| -173.608|      6.5| 30.0|\n",
            "|   -11.2|  165.416|      5.9| 30.0|\n",
            "|   -29.4| -177.169|      5.6| 35.0|\n",
            "|   -4.19|  141.183|      6.0| 35.0|\n",
            "| -17.021|  174.903|      6.8| 10.0|\n",
            "+--------+---------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview df_training\n",
        "df_training.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFYk3ieIcR-a",
        "outputId": "a637e911-6417-4edf-d413-1ea9cab9ce3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+---------+-----+\n",
            "|Latitude|Longitude|Magnitude|Depth|\n",
            "+--------+---------+---------+-----+\n",
            "|  51.096| -179.392|      5.6| 45.0|\n",
            "| -35.513|  -16.211|      6.0| 33.0|\n",
            "|  61.909| -149.738|      5.9| 66.0|\n",
            "|  -7.885|  109.014|      5.7|113.0|\n",
            "| -16.943|  -69.114|      6.3|172.0|\n",
            "+--------+---------+---------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview df_testing\n",
        "df_testing.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "U_PirHmUcR-a"
      },
      "outputs": [],
      "source": [
        "# Drop records with null values from our dataframes\n",
        "df_testing = df_testing.dropna()\n",
        "df_training = df_training.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "W45UeZp9cR-a"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import RandomForestRegressor\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gmMzfh9xcR-a"
      },
      "outputs": [],
      "source": [
        "# Select features to parse into our model and then create the feature vector\n",
        "assembler = VectorAssembler(inputCols=['Latitude', 'Longitude', 'Depth'], outputCol='features')\n",
        "\n",
        "# Create the Model\n",
        "model_reg = RandomForestRegressor(featuresCol='features', labelCol='Magnitude')\n",
        "\n",
        "# Chain the assembler with the model in a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, model_reg])\n",
        "\n",
        "# Train the Model\n",
        "model = pipeline.fit(df_training)\n",
        "\n",
        "# Make the prediction\n",
        "pred_results = model.transform(df_testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0lK6X42cR-a",
        "outputId": "1dbecc6f-a4ef-4ca0-9d05-5cc6344cea94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+---------+-----+--------------------+-----------------+\n",
            "|Latitude|Longitude|Magnitude|Depth|            features|       prediction|\n",
            "+--------+---------+---------+-----+--------------------+-----------------+\n",
            "|  51.096| -179.392|      5.6| 45.0|[51.096,-179.392,...|5.832700238333824|\n",
            "| -35.513|  -16.211|      6.0| 33.0|[-35.513,-16.211,...|5.829089472289315|\n",
            "|  61.909| -149.738|      5.9| 66.0|[61.909,-149.738,...|5.860084330908842|\n",
            "|  -7.885|  109.014|      5.7|113.0|[-7.885,109.014,1...|5.851281509322248|\n",
            "| -16.943|  -69.114|      6.3|172.0|[-16.943,-69.114,...|5.876063892064326|\n",
            "+--------+---------+---------+-----+--------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Preview pred_results dataframe\n",
        "pred_results.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t63kLUptcR-b",
        "outputId": "40f59fcc-5d84-4afc-fd05-f935f20c40fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 0.417558\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "# rmse should be less than 0.5 for the model to be useful\n",
        "evaluator = RegressionEvaluator(labelCol='Magnitude', predictionCol='prediction', metricName='rmse')\n",
        "rmse = evaluator.evaluate(pred_results)\n",
        "print('Root Mean Squared Error (RMSE) on test data = %g' % rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CABrqyKzcR-b",
        "outputId": "672f4387-4662-4cf8-e526-3f853e6b2741"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCreate the prediction dataset\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "\"\"\"\n",
        "Create the prediction dataset\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pauy14ecR-b",
        "outputId": "ffb77918-ccc8-47e6-ca9f-e747987e5fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----------------+----+------------------+\n",
            "|Latitude|Longitude|   Pred_Magnitude|Year|              RMSE|\n",
            "+--------+---------+-----------------+----+------------------+\n",
            "|  51.096| -179.392|5.832700238333824|2017|0.4175577273202706|\n",
            "| -35.513|  -16.211|5.829089472289315|2017|0.4175577273202706|\n",
            "|  61.909| -149.738|5.860084330908842|2017|0.4175577273202706|\n",
            "|  -7.885|  109.014|5.851281509322248|2017|0.4175577273202706|\n",
            "| -16.943|  -69.114|5.876063892064326|2017|0.4175577273202706|\n",
            "+--------+---------+-----------------+----+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the prediction dataset\n",
        "df_pred_results = pred_results['Latitude', 'Longitude', 'prediction']\n",
        "\n",
        "# Rename the prediction field\n",
        "df_pred_results = df_pred_results.withColumnRenamed('prediction', 'Pred_Magnitude')\n",
        "\n",
        "# Add more columns to our prediction dataset\n",
        "df_pred_results = df_pred_results.withColumn('Year', lit(2017))\\\n",
        "    .withColumn('RMSE', lit(rmse))\n",
        "\n",
        "# Preview df_pred_results\n",
        "df_pred_results.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6obLc8aAcR-b",
        "outputId": "65fb0f3d-73a9-4f6f-f1a2-b1a910c119ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results saved as CSV file at: /content/pred_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the prediction results DataFrame to a CSV file\n",
        "output_path = \"/content/pred_results.csv\"\n",
        "df_pred_results.write.format(\"csv\") \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .option(\"header\", \"true\") \\\n",
        "    .save(output_path)\n",
        "\n",
        "print(f\"Prediction results saved as CSV file at: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9cGyX6RcR-b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzJij0uccR-b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jqSKydAcR-b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}